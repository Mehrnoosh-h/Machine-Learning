{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvkXCSfQPz9z"
   },
   "source": [
    "**Univariate Multi-Step LSTM Models**\n",
    "\n",
    "A time series forecasting problem that requires a prediction of multiple time steps into the future can be referred to as multi-step time series forecasting.\n",
    "\n",
    "Specifically, these are problems where the forecast horizon or interval is more than one time step.\n",
    "\n",
    "There are two main types of LSTM models that can be used for multi-step forecasting; they are:\n",
    "\n",
    "1- Vector Output Model\n",
    "\n",
    "2- Encoder-Decoder Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c intel mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install tensorflow-gpu=2.3 tensorflow=2.3=mkl_py37h936c3e2_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.10.0-cp39-cp39-macosx_10_14_x86_64.whl (241.2 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp39-cp39-macosx_10_10_x86_64.whl (4.5 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-macosx_10_9_x86_64.whl (980 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.0-py2.py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/mehrnooshhasanzade/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras-preprocessing, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.10.26 gast-0.4.0 google-auth-2.14.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyiNzcImddcM"
   },
   "outputs": [],
   "source": [
    "# univariate stacked lstm example\n",
    "import pandas as pd A\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "#for CNN and Conv LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReStvf1bc0T4"
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('dma.csv', hea2der=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "dma_df = pd.DataFrame(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQQBitJwEdW_"
   },
   "outputs": [],
   "source": [
    "# reading CSV file\n",
    "data = pd.read_csv('dma.csv')\n",
    "\n",
    " \n",
    "# converting column data to list\n",
    "date_week = data['date_week'].tolist()\n",
    "dma = data['DMA_CODE'].tolist()\n",
    "TOTAL_NURTEC_NBRX = data['TOTAL_NURTEC_NBRX'].tolist()\n",
    "df= list(zip(dma, date_week, TOTAL_NURTEC_NBRX))\n",
    "dma_df = pd.DataFrame(df, columns=['dma', 'date_week','TOTAL_NURTEC_NBRX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW_b3grlJdQT",
    "outputId": "3671a830-b778-41f6-f216-a206d7ac54bc"
   },
   "outputs": [],
   "source": [
    "dma_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhQx4N8KJ6rk",
    "outputId": "2655d763-bc0f-4f14-c091-58b639a3f74d"
   },
   "outputs": [],
   "source": [
    "dma_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "g9JVqBsOFhsm",
    "outputId": "9f242410-90e6-4777-f89f-1b4f30a8ab92"
   },
   "outputs": [],
   "source": [
    "dma_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PLXl3OapZ0s"
   },
   "source": [
    "\n",
    "Before we look at these models, let’s first look at the preparation of data for multi-step forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3WaX-rIxp9Z"
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-E5LUnX0O0E"
   },
   "source": [
    "**Vector Output Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keD6shpD0akF"
   },
   "source": [
    "The LSTM expects data to have a three-dimensional structure of \n",
    "\n",
    "[samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkiDmi1YxqOk"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "def vector_model(n_steps_in, n_steps_out, n_features , ep ):\n",
    "  vector_model = Sequential()\n",
    "  vector_model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "  vector_model.add(LSTM(100, activation='relu'))\n",
    "  vector_model.add(Dense(n_steps_out))\n",
    "  vector_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "  # fit model\n",
    "  vector_model.fit(X, y, epochs= ep, verbose=0)\n",
    "\n",
    "  # demonstrate prediction\n",
    "  df1 = dma_df.iloc[-3: , :]\n",
    "  x_input = df1['TOTAL_NURTEC_NBRX']\n",
    "  x_input = array(x_input )\n",
    "\n",
    "  x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "  yhat = vector_model.predict(x_input, verbose=0)\n",
    "  return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sm-OjyR1evD"
   },
   "source": [
    "**Encoder-Decoder Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3MctOhl1paa"
   },
   "source": [
    "A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM.\n",
    "\n",
    "The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another.\n",
    "\n",
    "This model can be used for multi-step time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gplg3Ac9xqBy"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "def encoder_decoder_model(n_steps_in, n_steps_out, n_features, ep):\n",
    "  encoder_model = Sequential()\n",
    "  encoder_model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "  encoder_model.add(RepeatVector(n_steps_out))\n",
    "  encoder_model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "  encoder_model.add(TimeDistributed(Dense(1)))\n",
    "  encoder_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "  # fit model\n",
    "  encoder_model.fit(X, y, epochs=ep, verbose=0)\n",
    "\n",
    "  # demonstrate prediction\n",
    "  df1 = dma_df.iloc[-3: , :]\n",
    "  x_input = df1['TOTAL_NURTEC_NBRX']\n",
    "  x_input = array(x_input )\n",
    "  x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "  yhat = encoder_model.predict(x_input, verbose=0)\n",
    "\n",
    "  return yhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk6fBFyr40Al"
   },
   "source": [
    "**Running models on DMA daat:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2QHKIJtuzNB",
    "outputId": "edf429bb-f76b-42f4-e47b-6a4f9aad80d3"
   },
   "outputs": [],
   "source": [
    "dma = []\n",
    "v_model = []\n",
    "e_model = []\n",
    "\n",
    "for item in dma_df['dma'].unique():\n",
    "  raw_seq= dma_df['TOTAL_NURTEC_NBRX']\n",
    "  print(item)\n",
    "  n_steps_in, n_steps_out = 3, 2\n",
    "  X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "  n_features = 1\n",
    "  X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "  y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
    "  ep = 200\n",
    "  yhat_vector = vector_model(n_steps_in, n_steps_out, n_features , ep )\n",
    "  yhat_encoder = encoder_decoder_model(n_steps_in, n_steps_out, n_features, ep)\n",
    "  \n",
    "  dma.append(item)\n",
    "  v_model.append(yhat_vector)\n",
    "  e_model.append(yhat_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7wfcpXX9Am6"
   },
   "outputs": [],
   "source": [
    "dma_prediction = pd.DataFrame(\n",
    "    {'DMA': dma,\n",
    "     'vector_model': v_model,\n",
    "     'encoder_model': e_model\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "1x_un-ViGGr4",
    "outputId": "65735848-a89d-4708-cd0f-b2a5811b681d"
   },
   "outputs": [],
   "source": [
    "dma_prediction"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
