{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvkXCSfQPz9z"
   },
   "source": [
    "Univariate LSTM Models\n",
    "\n",
    "\n",
    "1- Vanilla LSTM\n",
    "\n",
    "2- Stacked LSTM\n",
    "\n",
    "3- Bidirectional LSTM\n",
    "\n",
    "4- CNN LSTM\n",
    "\n",
    "5- ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyiNzcImddcM"
   },
   "outputs": [],
   "source": [
    "# univariate stacked lstm example\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "#for CNN and Conv LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PN6tNq-4c0XR",
    "outputId": "caf439bb-778e-4a29-da06-7ffb65769a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're running Colab\n",
      "Colab: mounting Google drive on  /content/gdrive\n",
      "Mounted at /content/gdrive\n",
      "\n",
      "Colab: making sure  /content/gdrive/My Drive/Colab Notebooks/forecasting/  exists.\n",
      "\n",
      "Colab: Changing directory to  /content/gdrive/My Drive/Colab Notebooks/forecasting/\n",
      "/content/gdrive/My Drive/Colab Notebooks/forecasting\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "#@title\n",
    "if IN_COLAB:\n",
    "  # Mount the Google Drive at mount\n",
    "  mount='/content/gdrive'\n",
    "  print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "  drive.mount(mount)\n",
    "\n",
    "  # Switch to the directory on the Google Drive that you want to use\n",
    "  import os\n",
    "  drive_root = mount + \"/My Drive/Colab Notebooks/forecasting/\"\n",
    "  \n",
    "  # Create drive_root if it doesn't exist\n",
    "  create_drive_root = True\n",
    "  if create_drive_root:\n",
    "    print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
    "    os.makedirs(drive_root, exist_ok=True)\n",
    "  \n",
    "  # Change to the directory\n",
    "  print(\"\\nColab: Changing directory to \", drive_root)\n",
    "  %cd $drive_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReStvf1bc0T4",
    "outputId": "624746e0-781e-4ee9-84b2-03e8c845e538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Nurtec Rx\n",
      "date_week            \n",
      "2020-09-04   4108.538\n",
      "2020-09-11   3200.286\n",
      "2020-09-18   3966.593\n",
      "2020-09-25   3935.653\n",
      "2020-10-02   4093.173\n",
      "...               ...\n",
      "2022-07-29   6780.315\n",
      "2022-08-05   6878.218\n",
      "2022-08-12   7069.195\n",
      "2022-08-19   7132.550\n",
      "2022-08-26   7437.977\n",
      "\n",
      "[104 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "series = pd.read_csv('data.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "df = pd.DataFrame(series)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cu53sZX8nDM"
   },
   "outputs": [],
   "source": [
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urR-j-JM8u02"
   },
   "outputs": [],
   "source": [
    "#  define input sequence\n",
    "raw_seq= df['Nurtec Rx']\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "n_features = 1\n",
    "epochs = 200\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9jF4UxdhMCB",
    "outputId": "ed22cae5-3024-4a7c-c266-d7e788cb8fd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7069.195, 7132.55 , 7437.977])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[-(n_steps): , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "x_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYjF_Uuw81KS"
   },
   "source": [
    "**Vanila LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VO_CSlUe8uyj",
    "outputId": "422529dc-77ef-4fe5-902f-025cd5e93424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7273.626]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define model\n",
    "vanila_model = Sequential()\n",
    "vanila_model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "vanila_model.add(Dense(1))\n",
    "vanila_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "vanila_model.fit(X, y, epochs= epochs, verbose=0)\n",
    "\n",
    "# demonstrate prediction. -----Same for Vanila and Stacked & Bidirectional\n",
    "df1 = df.iloc[-(n_steps): , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = vanila_model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1hAbFN19fBy"
   },
   "source": [
    "**Stacked LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTR_URzq8utK",
    "outputId": "23f6ae87-4fc1-4665-c8c4-83833778b316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7134.1636]]\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "seq_model = Sequential()\n",
    "seq_model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "seq_model.add(LSTM(50, activation='relu'))\n",
    "seq_model.add(Dense(1))\n",
    "seq_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# fit model\n",
    "seq_model.fit(X, y, epochs= epochs, verbose=0)\n",
    "\n",
    "# demonstrate prediction. -----Same for Vanila and Stacked & Bidirectional\n",
    "df1 = df.iloc[-(n_steps): , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = seq_model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0X6zcHUCKfB"
   },
   "source": [
    "**Bidirectional LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpTlP1Ga8ujL",
    "outputId": "e8eab176-0328-4c50-980c-5088a4fc7490"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18cbcc7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7232.447]]\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "bi_model = Sequential()\n",
    "bi_model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "bi_model.add(Dense(1))\n",
    "bi_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "bi_model.fit(X, y, epochs= epochs, verbose=0)\n",
    "# demonstrate prediction. -----Same for Vanila and Stacked & Bidirectional\n",
    "df1 = df.iloc[-(n_steps): , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = bi_model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq9RglWtDNuq"
   },
   "source": [
    "**CNN LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIpFgzQwrnLC"
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwcbWmdErtkA"
   },
   "outputs": [],
   "source": [
    "raw_seq= df['Nurtec Rx']\n",
    "n_steps = 4\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "epochs = 500\n",
    "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiIH2lCfDO-W",
    "outputId": "9c95b36e-4e36-4900-81da-d1ac20c85185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18c9a65b10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "cnn_model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "cnn_model.add(TimeDistributed(Flatten()))\n",
    "cnn_model.add(LSTM(50, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "cnn_model.fit(X, y, epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXFNSwAyGQ9q",
    "outputId": "178aef73-fe9e-4e69-cb71-0887753655be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18cae51830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7029.7334]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction CNN\n",
    "df1 = df.iloc[-4: , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
    "\n",
    "yhat = cnn_model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsYgcJltGejf"
   },
   "source": [
    "**Conv LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hldnBNpJzii"
   },
   "source": [
    "The layer expects input as a sequence of two-dimensional images, therefore the shape of input data must be:\n",
    "\n",
    "[samples, timesteps, rows, columns, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9Q1N6_fGQ7A"
   },
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq= df['Nurtec Rx']\n",
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "epochs = 500\n",
    "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-ht_imtGQ4M",
    "outputId": "245ce1d4-24c0-47f9-b29d-ad78b50aa0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7143.6904]]\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=epochs, verbose=0)\n",
    "\n",
    "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCWxSQinGQt7",
    "outputId": "301eabb2-7fbe-4cca-cf76-82101d7bc530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7143.6904]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "df1 = df.iloc[-4: , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PLXl3OapZ0s"
   },
   "source": [
    "**Multi-Step LSTM Models**\n",
    "\n",
    "A time series forecasting problem that requires a prediction of multiple time steps into the future can be referred to as multi-step time series forecasting.\n",
    "\n",
    "Specifically, these are problems where the forecast horizon or interval is more than one time step.\n",
    "\n",
    "There are two main types of LSTM models that can be used for multi-step forecasting; they are:\n",
    "\n",
    "1- Vector Output Model\n",
    "\n",
    "2- Encoder-Decoder Model\n",
    "\n",
    "Before we look at these models, letâ€™s first look at the preparation of data for multi-step forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3WaX-rIxp9Z"
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq= df['Nurtec Rx']\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "# for i in range(len(X)):\n",
    "# \tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-E5LUnX0O0E"
   },
   "source": [
    "**Vector Output Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keD6shpD0akF"
   },
   "source": [
    "The LSTM expects data to have a three-dimensional structure of \n",
    "\n",
    "[samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkiDmi1YxqOk",
    "outputId": "9ef459f1-4c66-4e1c-ddc1-a06ddb5b2640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7269.6196 7357.276 ]]\n"
     ]
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# define model\n",
    "vector_model = Sequential()\n",
    "vector_model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "vector_model.add(LSTM(100, activation='relu'))\n",
    "vector_model.add(Dense(n_steps_out))\n",
    "vector_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "vector_model.fit(X, y, epochs=50, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "df1 = df.iloc[-3: , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = vector_model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sm-OjyR1evD"
   },
   "source": [
    "**Encoder-Decoder Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3MctOhl1paa"
   },
   "source": [
    "A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM.\n",
    "\n",
    "The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another.\n",
    "\n",
    "This model can be used for multi-step time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aTpxOTYxqIw"
   },
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq= df['Nurtec Rx']\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gplg3Ac9xqBy",
    "outputId": "94dc5bd9-55de-495e-d741-372ef5fb0da8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18c7546690>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "encoder_model = Sequential()\n",
    "encoder_model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "encoder_model.add(RepeatVector(n_steps_out))\n",
    "encoder_model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "encoder_model.add(TimeDistributed(Dense(1)))\n",
    "encoder_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "encoder_model.fit(X, y, epochs=100, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-1ywUc92IgP",
    "outputId": "5303a97c-7d8e-4c34-a97d-a9ab909c1cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[7254.747]\n",
      "  [7371.073]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# demonstrate prediction\n",
    "\n",
    "df1 = df.iloc[-3: , :]\n",
    "x_input = df1['Nurtec Rx']\n",
    "x_input = array(x_input )\n",
    "\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = encoder_model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
